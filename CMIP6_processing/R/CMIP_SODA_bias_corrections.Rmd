---
title: "SODA Bias Correction Testing"
author: "Adam A. Kemberling"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: TRUE
    toc_float:
        collapsed: FALSE
    code_folding: show
editor_options: 
  chunk_output_type: console

---

```{r setup, include=FALSE}

# Set knitr options
knitr::opts_chunk$set(echo = TRUE, message = F, warning = F, comment = NA)
options(knitr.kable.NA = '')

###__ Packages  ####
library(here)
library(raster)
library(janitor)
library(gmRi)
library(patchwork)
library(tidyverse)
library(knitr)



# Load the build code and stratification function
box_paths  <- research_access_paths(os.use = "unix")
mills_path <- box_paths$mills
res_path   <- box_paths$res
oisst_path <- box_paths$oisst_mainstays
cmip_path  <- shared.path("unix", "RES_Data", "CMIP6")
soda_path  <- shared.path("unix", "RES_Data", "SODA")

#### Set theme  ####
theme_set(theme_minimal())

#  color palette for quick raster displays
temp_pal <- rev(RColorBrewer::brewer.pal(n = 10, name = "RdBu"))

####  Functions  ####
source(here("CMIP6_processing/R/sdm_workflow_funs.R"))



####  Memory check Functions  ####
# Source: https://medium.com/@williamr/reducing-memory-usage-in-r-especially-for-regressions-8ed8070ae4d8
# Main function 
.ls.objects <- function (pos = 1, pattern, order.by,
                        decreasing=FALSE, head=FALSE, n=5) {
    napply <- function(names, fn) sapply(names, function(x)
                                         fn(get(x, pos = pos)))
    names <- ls(pos = pos, pattern = pattern)
    obj.class <- napply(names, function(x) as.character(class(x))[1])
    obj.mode <- napply(names, mode)
    obj.type <- ifelse(is.na(obj.class), obj.mode, obj.class)
    obj.prettysize <- napply(names, function(x) {
                           capture.output(format(utils::object.size(x), units = "auto")) })
    obj.size <- napply(names, object.size)
    obj.dim <- t(napply(names, function(x)
                        as.numeric(dim(x))[1:2]))
    vec <- is.na(obj.dim)[, 1] & (obj.type != "function")
    obj.dim[vec, 1] <- napply(names, length)[vec]
    out <- data.frame(obj.type, obj.size, obj.prettysize, obj.dim)
    names(out) <- c("Type", "Size", "PrettySize", "Rows", "Columns")
    if (!missing(order.by))
        out <- out[order(out[[order.by]], decreasing=decreasing), ]
    if (head)
        out <- head(out, n)
    out
}


# Shorthand function for easy accessof memory use
lsos <- function(..., n = 10) {
    .ls.objects(..., order.by = "Size", decreasing = TRUE, head = TRUE, n = n)
}

```



## Import CMIP Data

We've got 4 variables to bias correct from the CMIP data using SODA:

 1. Sea Surface Temperature   
 2. Bottom Temperature   
 3. Surface Salinity   
 4. Bottom Salinity
 
 
The trickiest part will be managing the dimension and variable names, and either breaking the data up by variable or trying to do everything in a unified way.


```{r}

# Choose a variable
pick_var <- "bot_sal"

# Load all the CMIP Scenarios - cropped to study area
cmip_data <- import_cmip_collection(cmip_var = pick_var)

```

## Check Date Structures

The cmip to anomalies function relies on a consistent naming structure of XYYYYMMDD to pull out the correct years and months. If this isn't the case the function as currently written will break.


```{r}
# which names are off? get min/max string length
name_structure <- map(cmip_data, function(cmip_stack){

    # Pull out some descriptive aspects of each
    name_range <-  range(str_length(names(cmip_stack)))
    time_dims <- dim(cmip_stack)[3]
    
    # start and end date
    
    data.frame("lname_min" = name_range[1],
               "lname_max" = name_range[2],
               "time_dim"  = time_dims)}) %>%
  bind_rows(.id = "cmip_source") %>%
  arrange(lname_min) %>%
  mutate(scenario_type = ifelse(str_detect(cmip_source, "historic"), "historic", "projection"))





# # String length of 2
# names(cmip_data[[ name_structure[1,"cmip_source"] ]])[c(1:4)]
# # String length of 9
# names(cmip_data[[ name_structure[2,"cmip_source"] ]])[c(1:3)]
# # String length of 11
# names(cmip_data[[ name_structure[3,"cmip_source"] ]])[c(1:3)]
# # String length of 20
# names(cmip_data[[ name_structure[7,"cmip_source"] ]])[c(1:3)]
# 
# # Are they consistent within groups
# # String length of 20
# names(cmip_data[[ name_structure[7,"cmip_source"] ]])[c(1,5, 780)]
# names(cmip_data[[ name_structure[50,"cmip_source"] ]])[c(1,5, 780)]
# 
# # Do time steps line up for different scenarios
historic_sources   <- name_structure %>% filter(scenario_type == "historic") %>% pull(cmip_source)
projection_sources <- name_structure %>% filter(scenario_type == "projection") %>% pull(cmip_source)

cmip_data[ which(names(cmip_data) %in% historic_sources) ] %>%
  map(~ names(.x)[c(1, 780)])

cmip_data[ which(names(cmip_data) %in% projection_sources) ] %>%
  map(~ names(.x)[c(1, 780)])


```



## CMIP Scenario Climatologies

Need two things now:

 1. CMIP6 Climatology for the variables we loaded
 2. The corresponding anomalies


```{r}

# Set start and end year for climatology - needs to match SODA climatology reference period
start_year <- 1990
end_year   <- 2019

cmip_clims <- imap(cmip_data, function(cmip_stack, cmip_name){
  
  # Get monthly climatology
  message(paste0("Processing Climatology: ", cmip_name))
  cmip_clim <- suppressMessages(cmip_to_clim(cmip_stack = cmip_stack, clim_years = c(start_year, end_year)))
  
  # return the climatology (should work b/c smaller)
  return(cmip_clim)})

```

## CMIP Scenario Anomalies

So we need to add a matching step to


```{r}
cmip_anoms <- map2(cmip_data, cmip_clims, function(cmip_data, cmip_clims){
  
  # Check for those trouble files
  if(class(cmip_clims) == "character"){
    return("Problem with CMIP Naming Structure")}
  
  # Use the our function to match months and return anomalies
  cmip_anomalies <- cmip_get_anomalies(cmip_data, cmip_clims)
  return(cmip_anomalies)
})
```




##  SODA Bias Correction

Now that we have the anomalies we can add them to the SODA climatology to get an unbiased dataset out.

```{r}

# Load SODA Climatology
soda_clim <- import_soda_clim(soda_var = "bot_sal")


####  Check/Resample Grids  ####
cmip_anoms_regrid <- map(cmip_anoms, function(anom_grid){
  if(class(anom_grid) == "character"){return("Problem with CMIP Naming Structure")}
  resample_grid(starting_grid = anom_grid, desired_grid = soda_clim_shifted)})


####  Match and Bias Correct
cmip_anoms_bcorrect <- map(cmip_anoms, function(anom_grid){
  if(class(anom_grid) == "character"){
    return("Problem with CMIP Naming Structure")}
  delta_method_bias_correct(cmip_grid = anom_grid, reference_climatology = soda_clim)})



# how they looking
plot(cmip_anoms_bcorrect$stGrid_so_CanESM5_r10i1p1f1_ssp585$X2015.01.16, 
     main = "Bias-Corrected Bottom Salinity\nstGrid_so_CanESM5_r10i1p1f1_ssp585\n2015-01-16")
```


## Processing Mean/5th/95th

```{r}

# Re-stack them as years?
names(cmip_anoms_bcorrect)[c(1:6)]
names(cmip_anoms_bcorrect[[1]])[c(1:6)]
names(cmip_anoms_bcorrect[[2]])[c(1:6)]



####  Different Treatments for Historical / Projections

# Name of scenarios that fall  into either category
historic_sources   <- name_structure %>% filter(scenario_type == "historic") %>% pull(cmip_source)
projection_sources <- name_structure %>% filter(scenario_type == "projection") %>% pull(cmip_source)

# what list numbers each group is in the bias corrected data
historic_i  <- which(names(cmip_anoms_bcorrect) %in% historic_sources)
projected_i <- which(names(cmip_anoms_bcorrect) %in% projection_sources)


# Get the mean 5th 95th
```

